{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Creating File Records - Batch 3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPK4/TcBVj536QzhVOAyqjc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cBEA2_i1kQyP"},"source":["## Creating File Records\n","\n","In this notebook, we will create the file recoreds for auxillary i.e. for each loan application in master file, we will fetch the records from auxillary files, take the mean or weighted mean and store that."]},{"cell_type":"code","metadata":{"id":"dETxryZs1RT9","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1601521195760,"user_tz":-330,"elapsed":23944,"user":{"displayName":"Himanshu Bhatnagar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtNnEEs3Vpa6DcPA5XsADQsENAWaVpGXrIB3zI=s64","userId":"16784833160241300445"}},"outputId":"a958e5c1-9851-472a-f2c5-180f9ea6c68a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CCUlX7JGgcW1"},"source":["# project directory\n","current_dir = 'Home Credit_Kaggle'\n","\n","# set the project folder as current working directory\n","import os\n","complete_path = os.path.join('/content/drive/My Drive/Colab Notebooks/',current_dir)\n","os.chdir(complete_path)\n","\n","# create output folder for file snapshots if not already present\n","out_path_data = os.path.join(complete_path,'final_data')\n","if not os.path.isdir(out_path_data):\n","  os.mkdir(out_path_data)\n","  # create folders for all batches\n","  batches_count = 7\n","  for b in range(batches_count):\n","    out_path_batch = os.path.join(out_path_data,'batch' + str(b+1))\n","    os.mkdir(out_path_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHDH-W3I7v1m"},"source":["import numpy as np\n","import pandas as pd\n","import time\n","from scipy.sparse import csr_matrix,save_npz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ld-VbN5jzIbh"},"source":["## Load control File"]},{"cell_type":"code","metadata":{"id":"XHyIDdGFZbSH","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"ok","timestamp":1601521443343,"user_tz":-330,"elapsed":1437,"user":{"displayName":"Himanshu Bhatnagar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtNnEEs3Vpa6DcPA5XsADQsENAWaVpGXrIB3zI=s64","userId":"16784833160241300445"}},"outputId":"1d555531-8c59-491c-fb3f-1e828b3bdbd3"},"source":["# load HomeCredit_Control File_File Level.csv\n","file_level_flags = pd.read_csv('control/HomeCredit_Control File_File Level_ml.csv')\n","print(file_level_flags.shape)\n","file_level_flags.head(6)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(6, 4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FILE_NAME</th>\n","      <th>NUM_TOP_REC</th>\n","      <th>ORDER_BY</th>\n","      <th>ASC ORDER?</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bureau.csv</td>\n","      <td>0</td>\n","      <td>SK_ID_CURR,SK_ID_BUREAU,DAYS_CREDIT</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>bureau_balance.csv</td>\n","      <td>0</td>\n","      <td>SK_ID_BUREAU,MONTHS_BALANCE</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>previous_application.csv</td>\n","      <td>0</td>\n","      <td>SK_ID_CURR,SK_ID_PREV,DAYS_DECISION</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>POS_CASH_balance.csv</td>\n","      <td>0</td>\n","      <td>SK_ID_CURR,SK_ID_PREV,MONTHS_BALANCE</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>installments_payments.csv</td>\n","      <td>0</td>\n","      <td>SK_ID_CURR,SK_ID_PREV,DAYS_INSTALMENT</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>credit_card_balance.csv</td>\n","      <td>0</td>\n","      <td>SK_ID_CURR,SK_ID_PREV,MONTHS_BALANCE</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   FILE_NAME  ...  ASC ORDER?\n","0                 bureau.csv  ...           1\n","1         bureau_balance.csv  ...           1\n","2   previous_application.csv  ...           1\n","3       POS_CASH_balance.csv  ...           1\n","4  installments_payments.csv  ...           1\n","5    credit_card_balance.csv  ...           1\n","\n","[6 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"2NrCYvSWqZYA","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1601521445851,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Himanshu Bhatnagar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtNnEEs3Vpa6DcPA5XsADQsENAWaVpGXrIB3zI=s64","userId":"16784833160241300445"}},"outputId":"9b1ddec8-d540-47db-ab39-9e81f46f838a"},"source":["# create a dictionary from above data using [FILE_NAME,FIELD_NAME] as key\n","# for fast lookup\n","\n","# prepare key as 'FILE_NAME' for each record\n","file_name_arr = np.asarray(file_level_flags['FILE_NAME'])\n","l = len(file_name_arr)\n","keys = [str(file_name_arr[i]).strip() for i in range(l)]\n","\n","# prepare values as ['NUM_TOP_REC','ORDER_BY','ASC_ORDER?'] for each record\n","num_top_rec_arr = np.asarray(file_level_flags['NUM_TOP_REC'])\n","order_by_arr = np.asarray(file_level_flags['ORDER_BY'])\n","asc_order_arr = np.asarray(file_level_flags['ASC ORDER?'])\n","values = [[num_top_rec_arr[i],order_by_arr[i],asc_order_arr[i]] for i in range(l)]\n","\n","# combined into dictionary\n","dict_file_flags = dict(zip(keys,values))\n","print(dict_file_flags.keys())\n","print(dict_file_flags.values())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['bureau.csv', 'bureau_balance.csv', 'previous_application.csv', 'POS_CASH_balance.csv', 'installments_payments.csv', 'credit_card_balance.csv'])\n","dict_values([[0, 'SK_ID_CURR,SK_ID_BUREAU,DAYS_CREDIT', 1], [0, 'SK_ID_BUREAU,MONTHS_BALANCE', 1], [0, 'SK_ID_CURR,SK_ID_PREV,DAYS_DECISION', 1], [0, 'SK_ID_CURR,SK_ID_PREV,MONTHS_BALANCE', 1], [0, 'SK_ID_CURR,SK_ID_PREV,DAYS_INSTALMENT', 1], [0, 'SK_ID_CURR,SK_ID_PREV,MONTHS_BALANCE', 1]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q2JP6u_tzL2e"},"source":["## Load Preprocessed Data"]},{"cell_type":"code","metadata":{"id":"OEfnf_W95skP","colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"status":"ok","timestamp":1601521258549,"user_tz":-330,"elapsed":62768,"user":{"displayName":"Himanshu Bhatnagar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtNnEEs3Vpa6DcPA5XsADQsENAWaVpGXrIB3zI=s64","userId":"16784833160241300445"}},"outputId":"4d0ebd11-eb70-4301-f1cd-673fca906635"},"source":["# load preprocessed data of files\n","\n","from scipy.sparse import load_npz\n","\n","# Application Train table\n","app_train_keys = pd.read_csv('preprocessed/app_train_keys.csv')\n","app_train_numeric_data = np.load('preprocessed/app_train_numeric_data.npy')\n","app_train_categ_data = load_npz('preprocessed/app_train_categ_data_csr.npz').todense()\n","print(app_train_keys.shape)\n","print(app_train_numeric_data.shape)\n","print(app_train_categ_data.shape)\n","print('='*120)\n"," \n","# Bureau table\n","bureau_keys = pd.read_csv('preprocessed/bureau_keys.csv')\n","bureau_numeric_data = np.load('preprocessed/bureau_numeric_data.npy')\n","bureau_categ_data = load_npz('preprocessed/bureau_categ_data_csr.npz').todense()\n","print(bureau_keys.shape)\n","print(bureau_numeric_data.shape)\n","print(bureau_categ_data.shape)\n","print('='*120)\n","\n","# Bureau balance table\n","bureau_bal_keys = pd.read_csv('preprocessed/bureau_bal_keys.csv')\n","bureau_bal_numeric_data = np.load('preprocessed/bureau_bal_numeric_data.npy')\n","bureau_bal_categ_data = load_npz('preprocessed/bureau_bal_categ_data_csr.npz').todense()\n","print(bureau_bal_keys.shape)\n","print(bureau_bal_numeric_data.shape)\n","print(bureau_bal_categ_data.shape)\n","print('='*120)\n","\n","# Previous Application\n","prev_app_keys = pd.read_csv('preprocessed/prev_app_keys.csv')\n","prev_app_numeric_data = np.load('preprocessed/prev_app_numeric_data.npy')\n","prev_app_categ_data = load_npz('preprocessed/prev_app_categ_data_csr.npz').todense()\n","print(prev_app_keys.shape)\n","print(prev_app_numeric_data.shape)\n","print(prev_app_categ_data.shape)\n","print('='*120)\n","\n","# POS CASH Balance\n","pos_cash_bal_keys = pd.read_csv('preprocessed/pos_cash_bal_keys.csv')\n","pos_cash_bal_numeric_data = np.load('preprocessed/pos_cash_bal_numeric_data.npy')\n","pos_cash_bal_categ_data = load_npz('preprocessed/pos_cash_bal_categ_data_csr.npz').todense()\n","print(pos_cash_bal_keys.shape)\n","print(pos_cash_bal_numeric_data.shape)\n","print(pos_cash_bal_categ_data.shape)\n","print('='*120)\n","\n","# Instalments payments\n","instalm_paym_keys = pd.read_csv('preprocessed/instalm_paym_keys.csv')\n","instalm_paym_numeric_data = np.load('preprocessed/instalm_paym_numeric_data.npy')\n","print(instalm_paym_keys.shape)\n","print(instalm_paym_numeric_data.shape)\n","print('='*120)\n","\n","# Credit Card Balance\n","credit_bal_keys = pd.read_csv('preprocessed/credit_bal_keys.csv')\n","credit_bal_numeric_data = np.load('preprocessed/credit_bal_numeric_data.npy')\n","credit_bal_categ_data = load_npz('preprocessed/credit_bal_categ_data_csr.npz').todense()\n","print(credit_bal_keys.shape)\n","print(credit_bal_numeric_data.shape)\n","print(credit_bal_categ_data.shape)\n","print('='*120)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(307511, 2)\n","(307511, 27)\n","(307511, 188)\n","========================================================================================================================\n","(1716428, 2)\n","(1716428, 10)\n","(1716428, 23)\n","========================================================================================================================\n","(13649962, 1)\n","(13649962, 1)\n","(13649962, 8)\n","========================================================================================================================\n","(1670214, 2)\n","(1670214, 4)\n","(1670214, 162)\n","========================================================================================================================\n","(5000679, 2)\n","(5000679, 5)\n","(5000679, 8)\n","========================================================================================================================\n","(13605401, 2)\n","(13605401, 6)\n","========================================================================================================================\n","(3840312, 2)\n","(3840312, 13)\n","(3840312, 7)\n","========================================================================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rJWQXk7ysZnW"},"source":["##Function to calculate weighted mean of columns of a matrix"]},{"cell_type":"code","metadata":{"id":"5mUOHW2Asg-_"},"source":["def weighted_mean(array_2D):\n","  # array_2D => numpy array of size (rows, cols)\n","  array_2D = np.asarray(array_2D)\n","  rows,cols = array_2D.shape\n","\n","  # create an array of weights\n","  # of size (rows, 1)\n","  # integer weighted array\n","  #sum_wts = rows*(rows + 1) # sum of n natural numbers\n","  #wts_arr = np.asarray([i/sum_wts for i in range(rows,0,-1)]).reshape(-1,1)\n","  # exponential decay array\n","  # weights are like 1,0.1,0.001...\n","  sum_wts = 1 * ((1 - (0.1**rows))/(1 - 0.1)) # sum of gp\n","  #print(sum_wts)\n","  wts_arr = np.asarray([(10**(-i))/sum_wts for i in range(0,rows)]).reshape(-1,1)\n","  #print(wts_arr)\n","\n","  #print(wts_arr)\n","\n","  # multiply this array elementwise with array_2D\n","  # numpy will automatically broadcast wts_arr to shape (rows,cols)\n","  #print(type(array_2D))\n","  #print(type(wts_arr))\n","  array_2D_wtd = wts_arr * array_2D\n","  #print(array_2D_wtd)\n","\n","  # take columnwise mean of above array and return\n","  #return np.mean(array_2D_wtd,axis=0).reshape(1,-1)\n","  return np.sum(array_2D_wtd,axis=0).reshape(1,-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FK4oW-U4zYu0"},"source":["## Functions to calculate \"File Snapshots\" of every file for one loan ID"]},{"cell_type":"markdown","metadata":{"id":"k0ar0j3Tznbi"},"source":["### Bureau Table"]},{"cell_type":"code","metadata":{"id":"SeNLnlQIR5wb"},"source":["def input2_calc(sk_id_curr):\n","  # fetch the file level flags for this file\n","  file_name = 'bureau.csv'\n","  num_top_rec = dict_file_flags[file_name][0] # number of top records to be selected  \n","\n","  # fetch the list of bureau ids for this sk_id_curr\n","  selected_recs = bureau_keys[bureau_keys['SK_ID_CURR'] == sk_id_curr]\n","  selected_inds = selected_recs.index # indices of the selected records\n","  count_sel_recs = len(selected_inds) # no of selected records\n","  #print(count_sel_recs)\n","\n","  inp2_numeric = np.array([[]]) # should be of shape (num_top_rec + 1 X length of one row of numeric values for bureau)\n","  inp2_categ = np.array([[]]) # should be of shape (num_top_rec + 1 X length of one row of categ values for bureau)\n","  if count_sel_recs > 0 and count_sel_recs <= num_top_rec:\n","    # calculate starting and ending indices\n","    s_ind = selected_inds[0] # first index\n","    e_ind = selected_inds[-1] # last index, since now there are <= num_top_rec records\n","\n","    # store numerical data\n","    inp2_numeric = bureau_numeric_data[s_ind:e_ind+1,:]\n","    # store categorical data\n","    inp2_categ = bureau_categ_data[s_ind:e_ind+1,:]\n","\n","    # zero padding \n","    no_zero_recs = num_top_rec - count_sel_recs + 1 # no of all zero records required for padding\n","\n","    # for numerical data\n","    noofcols_numeric = bureau_numeric_data.shape[1]\n","    padding_numeric = np.zeros((no_zero_recs,noofcols_numeric))\n","    inp2_numeric = np.append(inp2_numeric,padding_numeric,axis=0)\n","\n","    # for categorical data\n","    noofcols_categ = bureau_categ_data.shape[1]\n","    padding_categ = np.zeros((no_zero_recs,noofcols_categ))\n","    inp2_categ = np.append(inp2_categ,padding_categ,axis=0)\n","\n","  elif count_sel_recs > num_top_rec:\n","\n","    if num_top_rec > 0: # if any selected records are required\n","      # calculate starting and ending indices\n","      s_ind = selected_inds[0] # first index\n","      e_ind = selected_inds[num_top_rec-1] # ending index, since now there are >num_top_rec records\n","\n","      # store numerical data\n","      inp2_numeric = bureau_numeric_data[s_ind:e_ind+1,:]\n","      # store categorical data\n","      inp2_categ = bureau_categ_data[s_ind:e_ind+1,:]\n","    \n","    # calculate columnwise mean of remaining data\n","    # calcualte starting and ending indices of remaining data\n","    s_ind = selected_inds[num_top_rec] # right after ending index\n","    e_ind = selected_inds[-1] # last index\n","\n","    # for numerical data\n","    if calc_wtd_mean:\n","      mean_numeric = weighted_mean(bureau_numeric_data[s_ind:e_ind+1,:])\n","    else:\n","      mean_numeric = np.mean(bureau_numeric_data[s_ind:e_ind+1,:],axis=0).reshape(1,-1)\n","    \n","    if num_top_rec > 0:\n","      inp2_numeric = np.append(inp2_numeric,mean_numeric,axis=0)\n","    else:\n","      inp2_numeric = mean_numeric\n","\n","    # for categorical data\n","    if calc_wtd_mean:    \n","      mean_categ = weighted_mean(bureau_categ_data[s_ind:e_ind+1,:])      \n","    else:\n","      mean_categ = np.mean(bureau_categ_data[s_ind:e_ind+1,:],axis=0).reshape(1,-1)\n","    \n","    if num_top_rec > 0:\n","      inp2_categ = np.append(inp2_categ,mean_categ,axis=0)\n","    else:\n","      inp2_categ = mean_categ\n","\n","  else: #count_sel_recs == 0\n","    # zero padding \n","    no_zero_recs = num_top_rec + 1 # no of all zero records required for padding\n","\n","    # for numerical data\n","    noofcols_numeric = bureau_numeric_data.shape[1]\n","    padding_numeric = np.zeros((no_zero_recs,noofcols_numeric))\n","    inp2_numeric = padding_numeric\n","\n","    # for categorical data\n","    noofcols_categ = bureau_categ_data.shape[1]\n","    padding_categ = np.zeros((no_zero_recs,noofcols_categ))\n","    inp2_categ = padding_categ\n","  \n","  #===========end of if elif block============#\n","\n","  return inp2_numeric,inp2_categ,selected_recs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rMgqLDZ7zuQm"},"source":["### Bureau Balance Table"]},{"cell_type":"code","metadata":{"id":"LoSl_vXDfg9x"},"source":["def input3_calc(sk_id_bur_id):\n","  # fetch the file level flags for this file and bureau.csv file\n","  file_name = 'bureau_balance.csv'\n","  num_top_rec = dict_file_flags[file_name][0] # number of top records to be selected    \n","  #print(sk_id_bur_id.head())\n","\n","  # extract distinct bureau id from list of sk_id_curr + bureau ID\n","  sk_id_burr = pd.DataFrame()\n","  sk_id_burr['SK_ID_BUREAU'] = sk_id_bur_id['SK_ID_BUREAU'].unique()\n","  #print(sk_id_burr.head())\n","\n","  # array to store final data\n","  inp3_final = np.array([[]]).reshape(0,1) \n","  # should be of shape (num_top_rec + 1) X (length of one row of (numeric + categ) values for bureau balance)\n","\n","  # for each pair of SK_ID_CURR and SK_ID_BUREAU\n","  for i,r in sk_id_burr.iterrows():\n","\n","    sk_id_bure = r['SK_ID_BUREAU']\n","\n","    # fetch the columns for this sk_id_bureau\n","    selected_recs = bureau_bal_keys[bureau_bal_keys['SK_ID_BUREAU'] == sk_id_bure]\n","    selected_inds = selected_recs.index # indices of the selected records\n","    count_sel_recs = len(selected_inds) # no of selected records\n","    #print(count_sel_recs)\n","\n","    if count_sel_recs == 0: # no records selected\n","      continue\n","\n","    # calculate starting and ending indices\n","    s_ind = selected_inds[0] # first index\n","    e_ind = selected_inds[-1] # last index\n","\n","    # store numerical data\n","    inp3_numeric = bureau_bal_numeric_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of numeric values for bureau bal)\n","    \n","    # store categorical data\n","    inp3_categ = bureau_bal_categ_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of categ values for bureau bal)\n","\n","    # concat numerical data with categorical data, since this file only has one numerical column\n","    inp3 = np.hstack((inp3_numeric,inp3_categ))\n","\n","    # append to final array\n","    if inp3_final.shape == (0,1):\n","      inp3_final = inp3\n","    else:\n","      inp3_final = np.append(inp3_final,inp3,axis=0)\n","\n","  #====================end of for loop==================#\n","\n","  # no of rows required in the final output other than last mean record\n","  no_of_rows_required = num_top_rec\n","\n","  if inp3_final.shape[0] <= no_of_rows_required and inp3_final.shape[0] > 0:\n","\n","    # zero padding \n","    no_zero_recs = no_of_rows_required - inp3_final.shape[0] + 1 # no of all zero records required for padding\n","\n","    noofcols = inp3_final.shape[1]\n","    padding_final = np.zeros((no_zero_recs,noofcols))\n","    inp3_final = np.append(inp3_final,padding_final,axis=0)\n","\n","  elif inp3_final.shape[0] > no_of_rows_required:\n","\n","    # calculate starting index, ending index will be last\n","    s_ind = no_of_rows_required # first index after required data\n","  \n","    # calculate columnwise mean of remaining data after no_of_rows_required\n","\n","    if calc_wtd_mean:        \n","      mean_final = weighted_mean(inp3_final[s_ind:,:])\n","    else:\n","      mean_final = np.mean(inp3_final[s_ind:,:],axis=0).reshape(1,-1)    \n","    #print(mean_final)\n","\n","    # keep only top no_of_rows_required in inp3_final\n","    inp3_final = inp3_final[:no_of_rows_required]  \n","    \n","    # append the mean row\n","    if no_of_rows_required > 0: # if any selected rows are required\n","      inp3_final = np.append(inp3_final,mean_final,axis=0)\n","    else:\n","      inp3_final = mean_final\n","\n","  else: # inp3_final.shape[0] == 0\n","    # zero padding \n","    no_zero_recs = no_of_rows_required + 1 # no of all zero records required for padding\n","\n","    # no of columns required in the output  \n","    noofcols_final = bureau_bal_numeric_data.shape[1] + bureau_bal_categ_data.shape[1]\n","\n","    padding_final = np.zeros((no_zero_recs,noofcols_final))\n","    inp3_final = padding_final\n","\n","  #===========end of if elif block============#\n","\n","  return inp3_final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zbqRp8pBzyHl"},"source":["### Previous Applications Table"]},{"cell_type":"code","metadata":{"id":"a9bKJIFTQwsC"},"source":["def input4_calc(sk_id_curr):\n","  # fetch the file level flags for this file\n","  file_name = 'previous_application.csv'\n","  num_top_rec = dict_file_flags[file_name][0] # number of top records to be selected  \n","\n","  # fetch the list of previous application ids for this sk_id_curr\n","  selected_recs = prev_app_keys[prev_app_keys['SK_ID_CURR'] == sk_id_curr]\n","  selected_inds = selected_recs.index # indices of the selected records\n","  count_sel_recs = len(selected_inds) # no of selected records\n","  #print(count_sel_recs)\n","\n","  inp4_numeric = np.array([[]]) # should be of shape (num_top_rec + 1 X length of one row of numeric values for prev_app)\n","  inp4_categ = np.array([[]]) # should be of shape (num_top_rec + 1 X length of one row of categ values for prev_app)\n","  if count_sel_recs > 0 and count_sel_recs <= num_top_rec:\n","    # calculate starting and ending indices \n","    s_ind = selected_inds[0] # first index\n","    e_ind = selected_inds[-1] # last index, since now there are <= num_top_rec records\n","\n","    # store numerical data\n","    inp4_numeric = prev_app_numeric_data[s_ind:e_ind+1,:]\n","    # store categorical data\n","    inp4_categ = prev_app_categ_data[s_ind:e_ind+1,:]\n","\n","    # zero padding \n","    no_zero_recs = num_top_rec - count_sel_recs + 1 # no of all zero records required for padding\n","\n","    # for numerical data\n","    noofcols_numeric = prev_app_numeric_data.shape[1]\n","    padding_numeric = np.zeros((no_zero_recs,noofcols_numeric))\n","    inp4_numeric = np.append(inp4_numeric,padding_numeric,axis=0)\n","\n","    # for categorical data\n","    noofcols_categ = prev_app_categ_data.shape[1]\n","    padding_categ = np.zeros((no_zero_recs,noofcols_categ))\n","    inp4_categ = np.append(inp4_categ,padding_categ,axis=0)\n","\n","  elif count_sel_recs > num_top_rec:\n","\n","    if num_top_rec > 0: # if selected records are required\n","      # calculate starting and ending indices\n","      s_ind = selected_inds[0] # first index\n","      e_ind = selected_inds[num_top_rec-1] # ending index, since now there are >num_top_rec records\n","\n","      # store numerical data\n","      inp4_numeric = prev_app_numeric_data[s_ind:e_ind+1,:]\n","      # store categorical data\n","      inp4_categ = prev_app_categ_data[s_ind:e_ind+1,:]\n","    \n","    # calculate columnwise mean of remaining data\n","    # calcualte starting and ending indices of remaining data\n","    s_ind = selected_inds[num_top_rec] # right after ending index\n","    e_ind = selected_inds[-1] # last index\n","\n","    # for numerical data\n","    if calc_wtd_mean:            \n","      mean_numeric = weighted_mean(prev_app_numeric_data[s_ind:e_ind+1,:])\n","    else:\n","      mean_numeric = np.mean(prev_app_numeric_data[s_ind:e_ind+1,:],axis=0).reshape(1,-1)          \n","\n","    if num_top_rec > 0: \n","      inp4_numeric = np.append(inp4_numeric,mean_numeric,axis=0)\n","    else:\n","      inp4_numeric = mean_numeric\n","\n","    # for numerical data\n","    if calc_wtd_mean:\n","      mean_categ = weighted_mean(prev_app_categ_data[s_ind:e_ind+1,:])    \n","    else:\n","      mean_categ = np.mean(prev_app_categ_data[s_ind:e_ind+1,:],axis=0).reshape(1,-1)      \n","\n","    if num_top_rec > 0:\n","      inp4_categ = np.append(inp4_categ,mean_categ,axis=0)\n","    else:\n","      inp4_categ = mean_categ\n","  \n","  else: #count_sel_recs == 0\n","    # zero padding \n","    no_zero_recs = num_top_rec + 1 # no of all zero records required for padding\n","\n","    # for numerical data\n","    noofcols_numeric = prev_app_numeric_data.shape[1]\n","    padding_numeric = np.zeros((no_zero_recs,noofcols_numeric))\n","    inp4_numeric = padding_numeric\n","\n","    # for categorical data\n","    noofcols_categ = prev_app_categ_data.shape[1]\n","    padding_categ = np.zeros((no_zero_recs,noofcols_categ))\n","    inp4_categ = padding_categ\n","  \n","  #===========end of if elif block============#\n","\n","  return inp4_numeric,inp4_categ,selected_recs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LKJ7NmNGz2mL"},"source":["### POS Cash Balance Table"]},{"cell_type":"code","metadata":{"id":"VdRU2zKVUKjz"},"source":["def input5_calc(sk_id_prev_id):\n","  # fetch the file level flags for this file and bureau.csv file\n","  file_name = 'POS_CASH_balance.csv'\n","  num_top_rec = dict_file_flags[file_name][0] # number of top records to be selected    \n","\n","  # array to store final data\n","  inp5_final = np.array([[]]).reshape(0,1) \n","  # should be of shape (num_top_rec + 1) X (length of one row of (numeric + categ) values for POS CASH balance)\n","\n","  # for each pair of SK_ID_CURR and SK_ID_PREV\n","  for i,r in sk_id_prev_id.iterrows():\n","\n","    sk_id_curr = r['SK_ID_CURR']\n","    sk_id_prev = r['SK_ID_PREV']    \n","\n","    # fetch the columns for this sk_id_curr and sk_id_prev\n","    selected_recs = pos_cash_bal_keys[(pos_cash_bal_keys['SK_ID_CURR'] == sk_id_curr) & (pos_cash_bal_keys['SK_ID_PREV'] == sk_id_prev)]\n","    selected_inds = selected_recs.index # indices of the selected records\n","    count_sel_recs = len(selected_inds) # no of selected records\n","    #print(count_sel_recs)\n","\n","    if count_sel_recs == 0: # no records selected\n","      continue\n","\n","    # calculate starting and ending indices\n","    s_ind = selected_inds[0] # first index\n","    e_ind = selected_inds[-1] # last index\n","\n","    # store numerical data\n","    inp5_numeric = pos_cash_bal_numeric_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of numeric values for pos cash bal)\n","    \n","    # store categorical data\n","    inp5_categ = pos_cash_bal_categ_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of categ values for pos cash bal)\n","\n","    # concat numerical data with categorical data, since this file only has one numerical column\n","    inp5 = np.hstack((inp5_numeric,inp5_categ))\n","\n","    # append to final array\n","    if inp5_final.shape == (0,1):\n","      inp5_final = inp5\n","    else:\n","      inp5_final = np.append(inp5_final,inp5,axis=0)\n","\n","  #====================end of for loop==================#\n","\n","  # no of rows required in the final output other than last mean record\n","  no_of_rows_required = num_top_rec\n","\n","  if inp5_final.shape[0] <= no_of_rows_required and inp5_final.shape[0] > 0:\n","\n","    # zero padding \n","    no_zero_recs = no_of_rows_required - inp5_final.shape[0] + 1 # no of all zero records required for padding\n","\n","    noofcols = inp5_final.shape[1]\n","    padding_final = np.zeros((no_zero_recs,noofcols))\n","    inp5_final = np.append(inp5_final,padding_final,axis=0)\n","\n","  elif inp5_final.shape[0] > no_of_rows_required:\n","\n","    # calculate starting index, ending index will be last\n","    s_ind = no_of_rows_required # first index after required data\n","  \n","    # calculate columnwise mean of remaining data after no_of_rows_required\n","    if calc_wtd_mean:\n","      mean_final = weighted_mean(inp5_final[s_ind:,:])    \n","    else:\n","      mean_final = np.mean(inp5_final[s_ind:,:],axis=0).reshape(1,-1)      \n","    #print(mean_final)\n","\n","    # keep only top no_of_rows_required in inp5_final\n","    inp5_final = inp5_final[:no_of_rows_required]  \n","    \n","    # append the mean row\n","    if no_of_rows_required > 0:\n","      inp5_final = np.append(inp5_final,mean_final,axis=0)\n","    else:\n","      inp5_final = mean_final\n","\n","  else: #inp5_final.shape[0] == 0\n","    # zero padding \n","    no_zero_recs = no_of_rows_required + 1 # no of all zero records required for padding\n","\n","    # no of columns required in the output  \n","    noofcols_final = pos_cash_bal_numeric_data.shape[1] + pos_cash_bal_categ_data.shape[1]\n","\n","    padding_final = np.zeros((no_zero_recs,noofcols_final))\n","    inp5_final = padding_final\n","\n","  #===========end of if elif block============#\n","\n","  return inp5_final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yrk65MMbz6yX"},"source":["### Installments Payments Table"]},{"cell_type":"code","metadata":{"id":"Sb5k07EFohGS"},"source":["def input6_calc(sk_id_prev_id):\n","  # fetch the file level flags for this file and bureau.csv file\n","  file_name = 'installments_payments.csv'\n","  num_top_rec = dict_file_flags[file_name][0] # number of top records to be selected    \n","\n","  # array to store final data\n","  inp6_final = np.array([[]]).reshape(0,1) \n","  # should be of shape (num_top_rec + 1) X (length of one row of numeric values for Instalment payments)\n","\n","  # for each pair of SK_ID_CURR and SK_ID_PREV\n","  for i,r in sk_id_prev_id.iterrows():\n","\n","    sk_id_curr = r['SK_ID_CURR']\n","    sk_id_prev = r['SK_ID_PREV']    \n","\n","    # fetch the columns for this pair\n","    selected_recs = instalm_paym_keys[(instalm_paym_keys['SK_ID_CURR'] == sk_id_curr) & (instalm_paym_keys['SK_ID_PREV'] == sk_id_prev)]\n","    selected_inds = selected_recs.index # indices of the selected records\n","    count_sel_recs = len(selected_inds) # no of selected records\n","    #print(count_sel_recs)\n","\n","    if count_sel_recs == 0: # no records selected\n","      continue\n","\n","    # calculate starting and ending indices\n","    s_ind = selected_inds[0] # first index\n","    e_ind = selected_inds[-1] # last index\n","\n","    # store numerical data\n","    inp6_numeric = instalm_paym_numeric_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of numeric values for instalments payments)\n","    \n","    # set numerical data as final data\n","    inp6 = inp6_numeric\n","\n","    # append to final array\n","    if inp6_final.shape == (0,1):\n","      inp6_final = inp6\n","    else:\n","      inp6_final = np.append(inp6_final,inp6,axis=0)\n","\n","  #====================end of for loop==================#\n","\n","  # no of rows required in the final output other than last mean record\n","  no_of_rows_required = num_top_rec\n","\n","  if inp6_final.shape[0] <= no_of_rows_required and inp6_final.shape[0] > 0:\n","\n","    # zero padding \n","    no_zero_recs = no_of_rows_required - inp6_final.shape[0] + 1 # no of all zero records required for padding\n","\n","    noofcols = inp6_final.shape[1]\n","    padding_final = np.zeros((no_zero_recs,noofcols))\n","    inp6_final = np.append(inp6_final,padding_final,axis=0)\n","\n","  elif inp6_final.shape[0] > no_of_rows_required:\n","\n","    # calculate starting index, ending index will be last\n","    s_ind = no_of_rows_required # first index after required data\n","  \n","    # calculate columnwise mean of remaining data after no_of_rows_required\n","    if calc_wtd_mean:    \n","      mean_final = weighted_mean(inp6_final[s_ind:,:])        \n","    else:\n","      mean_final = np.mean(inp6_final[s_ind:,:],axis=0).reshape(1,-1)\n","\n","    #print(mean_final)\n","\n","    # keep only top no_of_rows_required in inp6_final\n","    inp6_final = inp6_final[:no_of_rows_required]  \n","    \n","    # append the mean row\n","    if no_of_rows_required > 0:\n","      inp6_final = np.append(inp6_final,mean_final,axis=0)\n","    else:\n","      inp6_final = mean_final\n","\n","  else: #inp6_final.shape[0] == 0\n","    # zero padding \n","    no_zero_recs = no_of_rows_required + 1 # no of all zero records required for padding\n","\n","    # no of columns required in the output  \n","    noofcols_final = instalm_paym_numeric_data.shape[1]\n","\n","    padding_final = np.zeros((no_zero_recs,noofcols_final))\n","    inp6_final = padding_final\n","\n","  #===========end of if elif block============#\n","\n","  return inp6_final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QtTlD2gVz_OO"},"source":["### Credit Card Balance Table"]},{"cell_type":"code","metadata":{"id":"ajuRL7iqwx2E"},"source":["def input7_calc(sk_id_prev_id):\n","  # fetch the file level flags for this file and bureau.csv file\n","  file_name = 'credit_card_balance.csv'\n","  num_top_rec = dict_file_flags[file_name][0] # number of top records to be selected    \n","\n","  # array to store final data\n","  inp7_final = np.array([[]]).reshape(0,1) \n","  # should be of shape (num_top_rec + 1) X (length of one row of (numeric + categ) values for Credit Card Balance)\n","\n","  # for each pair of SK_ID_CURR and SK_ID_PREV\n","  for i,r in sk_id_prev_id.iterrows():\n","\n","    sk_id_curr = r['SK_ID_CURR']\n","    sk_id_prev = r['SK_ID_PREV']    \n","\n","    # fetch the columns for this pair\n","    selected_recs = credit_bal_keys[(credit_bal_keys['SK_ID_CURR'] == sk_id_curr) & (credit_bal_keys['SK_ID_PREV'] == sk_id_prev)]\n","    selected_inds = selected_recs.index # indices of the selected records\n","    count_sel_recs = len(selected_inds) # no of selected records\n","    #print(count_sel_recs)\n","\n","    if count_sel_recs == 0: # no records selected\n","      continue\n","\n","    # calculate starting and ending indices\n","    s_ind = selected_inds[0] # first index\n","    e_ind = selected_inds[-1] # last index\n","\n","    # store numerical data\n","    inp7_numeric = credit_bal_numeric_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of numeric values for credit card balance)\n","    \n","    # store categorical data\n","    inp7_categ = credit_bal_categ_data[s_ind:e_ind+1,:] \n","    # will be of shape (count_sel_rec X length of one row of categ values for credit card balance)\n","\n","    # concat numerical data with categorical data, since this file only has one categorical column\n","    inp7 = np.hstack((inp7_numeric,inp7_categ))\n","\n","    # append to final array\n","    if inp7_final.shape == (0,1):\n","      inp7_final = inp7\n","    else:\n","      inp7_final = np.append(inp7_final,inp7,axis=0)\n","\n","  #====================end of for loop==================#\n","\n","  # no of rows required in the final output other than last mean record\n","  no_of_rows_required = num_top_rec\n","\n","  if inp7_final.shape[0] <= no_of_rows_required and inp7_final.shape[0] > 0:\n","\n","    # zero padding \n","    no_zero_recs = no_of_rows_required - inp7_final.shape[0] + 1 # no of all zero records required for padding\n","\n","    noofcols = inp7_final.shape[1]\n","    padding_final = np.zeros((no_zero_recs,noofcols))\n","    inp7_final = np.append(inp7_final,padding_final,axis=0)\n","\n","  elif inp7_final.shape[0] > no_of_rows_required:\n","\n","    # calculate starting index, ending index will be last\n","    s_ind = no_of_rows_required # first index after required data\n","  \n","    # calculate columnwise mean of remaining data after no_of_rows_required\n","    if calc_wtd_mean:    \n","      mean_final = weighted_mean(inp7_final[s_ind:,:])        \n","    else:\n","      mean_final = np.mean(inp7_final[s_ind:,:],axis=0).reshape(1,-1)      \n","    #print(mean_final)\n","\n","    # keep only top no_of_rows_required in inp5_final\n","    inp7_final = inp7_final[:no_of_rows_required]  \n","    \n","    # append the mean row\n","    if no_of_rows_required > 0:\n","      inp7_final = np.append(inp7_final,mean_final,axis=0)\n","    else:\n","      inp7_final = mean_final\n","\n","  else: #inp7_final.shape[0] == 0\n","    # zero padding \n","    no_zero_recs = no_of_rows_required + 1 # no of all zero records required for padding\n","\n","    # no of columns required in the output  \n","    noofcols_final = credit_bal_numeric_data.shape[1] + credit_bal_categ_data.shape[1]\n","\n","    padding_final = np.zeros((no_zero_recs,noofcols_final))\n","    inp7_final = padding_final\n","\n","  #===========end of if elif block============#\n","\n","  return inp7_final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l3R4jPFCBNO2"},"source":["##Generating data for each training point using above functions"]},{"cell_type":"code","metadata":{"id":"AlsKQTWrMcLP","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1601542306252,"user_tz":-330,"elapsed":9333031,"user":{"displayName":"Himanshu Bhatnagar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtNnEEs3Vpa6DcPA5XsADQsENAWaVpGXrIB3zI=s64","userId":"16784833160241300445"}},"outputId":"616d332f-feb1-49bd-a12d-83f7d8de3d6e"},"source":["def conv_3D_to_2D(array_3D):\n","  # to convert 3D array of shape (batch_size,rows,columns)\n","  # to 2D array of shape (batch_size*rows,columns)\n","  batch_size = int(array_3D.shape[0])\n","  rows = int(array_3D.shape[1])\n","  cols = int(array_3D.shape[2])\n","  return array_3D.reshape(batch_size*rows,cols)\n","##==========end of conv_3D_to_2D===========##\n","\n","# start time\n","s = time.time()\n","# start time for batch\n","s1 = time.time()\n","\n","# data corresponding to application train table\n","target_values = np.array([[]]) # final size should be no_of_rows X 1\n","input1_numeric_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric values for app_train\n","input1_categ_values = np.array([[]]) # final size should be no_of_rows X length of one hot categ values for app_train\n","\n","# data corresponding to bureau table\n","input2_numeric_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric values for bureau\n","input2_categ_values = np.array([[]]) # final size should be no_of_rows X length of one hot categ values for bureau\n","\n","# data corresponding to bureau balance table\n","input3_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric + categ values for bureau_bal\n","\n","# data corresponding to previous application table\n","input3_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric + categ values for bureau_bal\n","\n","# data corresponding to previous application table\n","input4_numeric_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric values for prev_app\n","input4_categ_values = np.array([[]]) # final size should be no_of_rows X length of one hot categ values for prev_app\n","\n","# data corresponding to POS Cash Balance table\n","input5_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric + categ values for pos_cash_bal\n","\n","# data corresponding to Instalments Payments table\n","input6_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric values for instalm_paym\n","\n","# data corresponding to Credit Card Balance table\n","input7_values = np.array([[]]) # final size should be no_of_rows X length of one row of numeric + categ values for credit_card_bal\n","\n","# for every SK_ID_CURR in app_train\n","\n","# subset the data into batch\n","batch_no = 3\n","rec_count = 45000\n","s_row = (batch_no - 1) * rec_count\n","e_row = (batch_no) * rec_count\n","app_train_keys_batch = app_train_keys[s_row:e_row]\n","# set weighted mean flag\n","calc_wtd_mean = False\n","\n","for i,r in app_train_keys_batch.iterrows():\n","  xi_id = r['SK_ID_CURR'] #loan ID\n","  yi = r['TARGET'].reshape(-1,1) #reshape to (1,1)\n","\n","  # append yi to target_values\n","  if target_values.shape == (1,0): #first point\n","    target_values = yi\n","  else:\n","    target_values = np.append(target_values,yi,axis=0)\n","\n","  #print(i) # test\n","  \n","  # calculate inputs for xi_id\n","  \n","  # input1 => corresponding to application_train table\n","  inp1_num = app_train_numeric_data[i,:].reshape(1,-1) # reshape to (1 X no of cols)\n","  #print(inp1_num.shape)\n","  inp1_cat = app_train_categ_data[i,:].reshape(1,-1) # reshape to (1 X no of cols)\n","  inp1_cat = np.expand_dims(inp1_cat,axis=0) # reshape to (1 X 1 X no of cols)\n","  #print(inp1_cat.shape)\n","\n","  # input2 => corresponding to bureau table\n","  inp2_num,inp2_cat,id_plus_bureauid_keys = input2_calc(xi_id)\n","  #print(inp2_num.shape)  \n","  #print(inp2_cat.shape)  \n","  # add one dimension to shape into => (1 X rows X columns)\n","  inp2_num = np.expand_dims(inp2_num,axis=0)\n","  inp2_cat = np.expand_dims(inp2_cat,axis=0)\n","\n","  # input3 => corresponding to bureau balance table\n","  inp3 = input3_calc(id_plus_bureauid_keys)\n","  # add one dimension to shape into => (1 X rows X columns)\n","  inp3 = np.expand_dims(inp3,axis=0)\n","\n","  # input4 => corresponding to previous application table\n","  inp4_num,inp4_cat,id_plus_prev_id_keys = input4_calc(xi_id)\n","  #print(inp4_num.shape)  \n","  #print(inp4_cat.shape)  \n","  # add one dimension to shape into => (1 X rows X columns)\n","  inp4_num = np.expand_dims(inp4_num,axis=0)\n","  inp4_cat = np.expand_dims(inp4_cat,axis=0)\n","\n","  # input5 => corresponding to POS cash balance table\n","  inp5 = input5_calc(id_plus_prev_id_keys)\n","  # add one dimension to shape into => (1 X rows X columns)\n","  inp5 = np.expand_dims(inp5,axis=0)\n","\n","  # input5 => corresponding to Instalments payments table\n","  inp6 = input6_calc(id_plus_prev_id_keys)\n","  # add one dimension to shape into => (1 X rows X columns)\n","  inp6 = np.expand_dims(inp6,axis=0)\n","\n","  # input7 => corresponding to Credit Card balance table\n","  inp7 = input7_calc(id_plus_prev_id_keys)\n","  # add one dimension to shape into => (1 X rows X columns)\n","  inp7 = np.expand_dims(inp7,axis=0)\n","\n","  # append the above arrays to final data\n","  if input1_numeric_values.shape == (1,0): # first point\n","    \n","    # input 1\n","    input1_numeric_values = inp1_num\n","    input1_categ_values = inp1_cat\n","\n","    # input 2\n","    input2_numeric_values = inp2_num\n","    input2_categ_values = inp2_cat\n","\n","    # input 3\n","    input3_values = inp3\n","\n","    # input 4\n","    input4_numeric_values = inp4_num\n","    input4_categ_values = inp4_cat\n","\n","    # input 5\n","    input5_values = inp5\n","\n","    # input 6\n","    input6_values = inp6\n","\n","    # input 7\n","    input7_values = inp7    \n","\n","  else:\n","\n","    # input 1\n","    input1_numeric_values = np.append(input1_numeric_values, inp1_num, axis=0)\n","    input1_categ_values = np.append(input1_categ_values, inp1_cat, axis=0)\n","\n","    # input 2\n","    input2_numeric_values = np.append(input2_numeric_values, inp2_num, axis=0)\n","    input2_categ_values = np.append(input2_categ_values, inp2_cat, axis=0)\n","\n","    # input 3\n","    input3_values = np.append(input3_values, inp3, axis=0)\n","\n","    # input 4\n","    input4_numeric_values = np.append(input4_numeric_values, inp4_num, axis=0)\n","    input4_categ_values = np.append(input4_categ_values, inp4_cat, axis=0)\n","\n","    # input 5\n","    input5_values = np.append(input5_values, inp5, axis=0)\n","\n","    # input 6\n","    input6_values = np.append(input6_values, inp6, axis=0)\n","\n","    # input 7\n","    input7_values = np.append(input7_values, inp7, axis=0)\n","\n","  # for every 1000 records processed\n","  # print time taken for 1000 records\n","  # and cumulative time taken\n","  if (i - s_row + 1) % 1000 == 0:\n","    print(\"{} records processed\".format(i - s_row + 1))\n","    print(\"Time Taken (In seconds) : \", (time.time() - s1))\n","    s1 = time.time()\n","    print(\"Total Time Taken (In seconds) : \", (time.time() - s))\n","    print('='*120)\n","    #break\n","  \n","  # for given number of records\n","  # save the data\n","  if (i + 1) == e_row:\n","    \n","    # for categorical and sparse data, we will flatten them to 2D\n","    # then convert to CSR first and then save\n","\n","    np.save(\"final_data/batch\"+str(batch_no)+\"/input1_numeric_values\",input1_numeric_values)\n","    input1_categ_values_flat = conv_3D_to_2D(input1_categ_values)\n","    input1_categ_values_csr = csr_matrix(input1_categ_values_flat)\n","    save_npz(\"final_data/batch\"+str(batch_no)+\"/input1_categ_values_csr.npz\",input1_categ_values_csr)\n","    \n","    np.save(\"final_data/batch\"+str(batch_no)+\"/target_values\",target_values)\n","\n","    np.save(\"final_data/batch\"+str(batch_no)+\"/input2_numeric_values\",input2_numeric_values)\n","    input2_categ_values_flat = conv_3D_to_2D(input2_categ_values)\n","    input2_categ_values_csr = csr_matrix(input2_categ_values_flat)\n","    save_npz(\"final_data/batch\"+str(batch_no)+\"/input2_categ_values_csr.npz\",input2_categ_values_csr)      \n","    \n","    input3_values_flat = conv_3D_to_2D(input3_values)\n","    input3_values_csr = csr_matrix(input3_values_flat)\n","    save_npz(\"final_data/batch\"+str(batch_no)+\"/input3_values_csr.npz\",input3_values_csr)\n","    \n","    np.save(\"final_data/batch\"+str(batch_no)+\"/input4_numeric_values\",input4_numeric_values)\n","    input4_categ_values_flat = conv_3D_to_2D(input4_categ_values)\n","    input4_categ_values_csr = csr_matrix(input4_categ_values_flat)\n","    save_npz(\"final_data/batch\"+str(batch_no)+\"/input4_categ_values_csr.npz\",input4_categ_values_csr)      \n","\n","    np.save(\"final_data/batch\"+str(batch_no)+\"/input5_values\",input5_values)\n","    np.save(\"final_data/batch\"+str(batch_no)+\"/input6_values\",input6_values)\n","    \n","    input7_values_flat = conv_3D_to_2D(input7_values)\n","    input7_values_csr = csr_matrix(input7_values_flat)\n","    save_npz(\"final_data/batch\"+str(batch_no)+\"/input7_values_csr.npz\",input7_values_csr)\n","\n","    print('='*5,'Data Saved for ' + str(e_row - s_row) + ' records','='*5)\n","    #break\n","\n","#===========end of for loop=================#\n","\n","#print(\"Time Taken (In seconds) :\", (time.time() - s))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000 records processed\n","Time Taken (In seconds) :  420.46372961997986\n","Total Time Taken (In seconds) :  420.46382451057434\n","========================================================================================================================\n","2000 records processed\n","Time Taken (In seconds) :  427.01064443588257\n","Total Time Taken (In seconds) :  847.4754803180695\n","========================================================================================================================\n","3000 records processed\n","Time Taken (In seconds) :  421.71967697143555\n","Total Time Taken (In seconds) :  1269.1952147483826\n","========================================================================================================================\n","4000 records processed\n","Time Taken (In seconds) :  424.52227115631104\n","Total Time Taken (In seconds) :  1693.717541694641\n","========================================================================================================================\n","5000 records processed\n","Time Taken (In seconds) :  411.06194710731506\n","Total Time Taken (In seconds) :  2104.7795383930206\n","========================================================================================================================\n","6000 records processed\n","Time Taken (In seconds) :  448.05079221725464\n","Total Time Taken (In seconds) :  2552.830403327942\n","========================================================================================================================\n","7000 records processed\n","Time Taken (In seconds) :  457.30199122428894\n","Total Time Taken (In seconds) :  3010.1324434280396\n","========================================================================================================================\n","8000 records processed\n","Time Taken (In seconds) :  437.64425683021545\n","Total Time Taken (In seconds) :  3447.7772731781006\n","========================================================================================================================\n","9000 records processed\n","Time Taken (In seconds) :  428.1944761276245\n","Total Time Taken (In seconds) :  3875.9718129634857\n","========================================================================================================================\n","10000 records processed\n","Time Taken (In seconds) :  413.63849401474\n","Total Time Taken (In seconds) :  4289.610362291336\n","========================================================================================================================\n","11000 records processed\n","Time Taken (In seconds) :  444.3085424900055\n","Total Time Taken (In seconds) :  4733.918958902359\n","========================================================================================================================\n","12000 records processed\n","Time Taken (In seconds) :  451.4541611671448\n","Total Time Taken (In seconds) :  5185.3731777668\n","========================================================================================================================\n","13000 records processed\n","Time Taken (In seconds) :  450.08281421661377\n","Total Time Taken (In seconds) :  5635.456039190292\n","========================================================================================================================\n","14000 records processed\n","Time Taken (In seconds) :  443.7514798641205\n","Total Time Taken (In seconds) :  6079.207560300827\n","========================================================================================================================\n","15000 records processed\n","Time Taken (In seconds) :  445.6397078037262\n","Total Time Taken (In seconds) :  6524.84805727005\n","========================================================================================================================\n","16000 records processed\n","Time Taken (In seconds) :  474.2225308418274\n","Total Time Taken (In seconds) :  6999.070625305176\n","========================================================================================================================\n","17000 records processed\n","Time Taken (In seconds) :  465.4731216430664\n","Total Time Taken (In seconds) :  7464.543816566467\n","========================================================================================================================\n","18000 records processed\n","Time Taken (In seconds) :  459.5915322303772\n","Total Time Taken (In seconds) :  7924.135400295258\n","========================================================================================================================\n","19000 records processed\n","Time Taken (In seconds) :  461.2836084365845\n","Total Time Taken (In seconds) :  8385.419048786163\n","========================================================================================================================\n","20000 records processed\n","Time Taken (In seconds) :  455.6036720275879\n","Total Time Taken (In seconds) :  8841.023684501648\n","========================================================================================================================\n","21000 records processed\n","Time Taken (In seconds) :  466.52478289604187\n","Total Time Taken (In seconds) :  9307.54851937294\n","========================================================================================================================\n","22000 records processed\n","Time Taken (In seconds) :  446.1571569442749\n","Total Time Taken (In seconds) :  9753.705732345581\n","========================================================================================================================\n","23000 records processed\n","Time Taken (In seconds) :  448.73742389678955\n","Total Time Taken (In seconds) :  10202.443204641342\n","========================================================================================================================\n","24000 records processed\n","Time Taken (In seconds) :  449.6258616447449\n","Total Time Taken (In seconds) :  10652.069123983383\n","========================================================================================================================\n","25000 records processed\n","Time Taken (In seconds) :  466.89845967292786\n","Total Time Taken (In seconds) :  11118.96762394905\n","========================================================================================================================\n","26000 records processed\n","Time Taken (In seconds) :  471.4528386592865\n","Total Time Taken (In seconds) :  11590.420505285263\n","========================================================================================================================\n","27000 records processed\n","Time Taken (In seconds) :  465.5041432380676\n","Total Time Taken (In seconds) :  12055.924705028534\n","========================================================================================================================\n","28000 records processed\n","Time Taken (In seconds) :  468.5046753883362\n","Total Time Taken (In seconds) :  12524.429435014725\n","========================================================================================================================\n","29000 records processed\n","Time Taken (In seconds) :  470.57388401031494\n","Total Time Taken (In seconds) :  12995.004132509232\n","========================================================================================================================\n","30000 records processed\n","Time Taken (In seconds) :  486.1416611671448\n","Total Time Taken (In seconds) :  13481.145859479904\n","========================================================================================================================\n","31000 records processed\n","Time Taken (In seconds) :  482.8571457862854\n","Total Time Taken (In seconds) :  13964.003053665161\n","========================================================================================================================\n","32000 records processed\n","Time Taken (In seconds) :  491.17794466018677\n","Total Time Taken (In seconds) :  14455.18192410469\n","========================================================================================================================\n","33000 records processed\n","Time Taken (In seconds) :  497.8620767593384\n","Total Time Taken (In seconds) :  14953.04492354393\n","========================================================================================================================\n","34000 records processed\n","Time Taken (In seconds) :  483.76679515838623\n","Total Time Taken (In seconds) :  15436.81178855896\n","========================================================================================================================\n","35000 records processed\n","Time Taken (In seconds) :  485.7514479160309\n","Total Time Taken (In seconds) :  15922.564049243927\n","========================================================================================================================\n","36000 records processed\n","Time Taken (In seconds) :  455.7225103378296\n","Total Time Taken (In seconds) :  16378.2873108387\n","========================================================================================================================\n","37000 records processed\n","Time Taken (In seconds) :  488.27471804618835\n","Total Time Taken (In seconds) :  16866.562078237534\n","========================================================================================================================\n","38000 records processed\n","Time Taken (In seconds) :  490.55283856391907\n","Total Time Taken (In seconds) :  17357.11497449875\n","========================================================================================================================\n","39000 records processed\n","Time Taken (In seconds) :  490.3952159881592\n","Total Time Taken (In seconds) :  17847.510239601135\n","========================================================================================================================\n","40000 records processed\n","Time Taken (In seconds) :  480.8954849243164\n","Total Time Taken (In seconds) :  18328.40580224991\n","========================================================================================================================\n","41000 records processed\n","Time Taken (In seconds) :  500.8456037044525\n","Total Time Taken (In seconds) :  18829.25145292282\n","========================================================================================================================\n","42000 records processed\n","Time Taken (In seconds) :  506.26380038261414\n","Total Time Taken (In seconds) :  19335.51529598236\n","========================================================================================================================\n","43000 records processed\n","Time Taken (In seconds) :  487.97125720977783\n","Total Time Taken (In seconds) :  19823.487188577652\n","========================================================================================================================\n","44000 records processed\n","Time Taken (In seconds) :  501.6573233604431\n","Total Time Taken (In seconds) :  20325.14550280571\n","========================================================================================================================\n","45000 records processed\n","Time Taken (In seconds) :  513.9305033683777\n","Total Time Taken (In seconds) :  20839.076066970825\n","========================================================================================================================\n","===== Data Saved for 45000 records =====\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AwwJ6KbLsdbK","colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"ok","timestamp":1601155385560,"user_tz":-330,"elapsed":17,"user":{"displayName":"Himanshu Bhatnagar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtNnEEs3Vpa6DcPA5XsADQsENAWaVpGXrIB3zI=s64","userId":"16784833160241300445"}},"outputId":"84ae0c8b-698b-4148-f307-dd63442bb589"},"source":["print(input1_numeric_values.shape)\n","print(input1_categ_values.shape)\n","print('='*120)\n","print(target_values.shape)\n","print('='*120)\n","print(input2_numeric_values.shape)\n","print(input2_categ_values.shape)\n","print('='*120)\n","print(input3_values.shape)\n","print('='*120)\n","print(input4_numeric_values.shape)\n","print(input4_categ_values.shape)\n","print('='*120)\n","print(input5_values.shape)\n","print('='*120)\n","print(input6_values.shape)\n","print('='*120)\n","print(input7_values.shape)\n","print('='*120)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(45000, 27)\n","(45000, 1, 188)\n","========================================================================================================================\n","(45000, 1)\n","========================================================================================================================\n","(45000, 3, 10)\n","(45000, 3, 23)\n","========================================================================================================================\n","(45000, 2, 9)\n","========================================================================================================================\n","(45000, 2, 4)\n","(45000, 2, 162)\n","========================================================================================================================\n","(45000, 11, 13)\n","========================================================================================================================\n","(45000, 6, 6)\n","========================================================================================================================\n","(45000, 11, 20)\n","========================================================================================================================\n"],"name":"stdout"}]}]}